{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\__init__.py:83\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMONAI requires Python \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPY_REQUIRED_MAJOR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPY_REQUIRED_MINOR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or higher. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the current Python is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_submodules  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# handlers_* have some external decorators the users may not have installed\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# *.so files and folder \"_C\" may not exist when the cpp extensions are not compiled\u001b[39;00m\n\u001b[0;32m     87\u001b[0m excludes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     88\u001b[0m     [\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(^(monai.handlers))\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     ]\n\u001b[0;32m     98\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\utils\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComponentStore\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MethodReplacer, RestartGenerator\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecate_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeprecatedError, deprecated, deprecated_arg, deprecated_arg_default\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RankFilter, evenly_divisible_all_gather, get_dist_device, string_list_all_gather\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     AdversarialIterationEvents,\n\u001b[0;32m     20\u001b[0m     AdversarialKeys,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     WSIPatchKeys,\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionType\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, TypeVar\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version_leq\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeprecatedError\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_arg_default\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\utils\\module.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionType, ModuleType\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Iterable, cast\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# bundle config system flags\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# set MONAI_EVAL_EXPR=1 to use 'eval', default value: run_eval=True\u001b[39;00m\n\u001b[0;32m     34\u001b[0m run_eval \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMONAI_EVAL_EXPR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\__init__.py:2623\u001b[0m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _running_with_deploy():\n\u001b[0;32m   2621\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compiler \u001b[38;5;28;01mas\u001b[39;00m compiler\n\u001b[1;32m-> 2623\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_TritonLibrary\u001b[39;00m:\n\u001b[0;32m   2624\u001b[0m         lib \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mLibrary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2625\u001b[0m         ops_table: _Dict[_Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], _Callable] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\__init__.py:2624\u001b[0m, in \u001b[0;36m_TritonLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_TritonLibrary\u001b[39;00m:\n\u001b[1;32m-> 2624\u001b[0m     lib \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtriton\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDEF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2625\u001b[0m     ops_table: _Dict[_Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], _Callable] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2627\u001b[0m     \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2628\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregisterOp\u001b[39m(\u001b[38;5;28mcls\u001b[39m, op_key, full_schema, op_impl, dispatch_key):\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\library.py:93\u001b[0m, in \u001b[0;36mLibrary.__init__\u001b[1;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[0;32m     91\u001b[0m frame \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mextract_stack(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     92\u001b[0m filename, lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineno\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mns \u001b[38;5;241m=\u001b[39m ns\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_defs: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "from monai.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "\n",
    "import glob\n",
    "import nibabel as nib\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"L:/Basic/divi/jstoker/slicer_pdac/Master Students WS 24/Martijn/data/Training/paired_scans\" #fill in training datapath\n",
    "nifti_images = sorted(glob.glob(os.path.join(data_dir, \"*.nii.gz\")))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedMedicalDataset(Dataset):\n",
    "    def __init__(self, image_pairs, metadata, labels, transform=None):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img1_path, img2_path = self.image_pairs[idx]\n",
    "        \n",
    "        # Load images using nibabel (for NIfTI)\n",
    "        img1 = nib.load(img1_path).get_fdata()\n",
    "        img2 = nib.load(img2_path).get_fdata()\n",
    "\n",
    "        # Add channel dimension for CNN input (C, H, W, D)\n",
    "        img1 = np.expand_dims(img1, axis=0)\n",
    "        img2 = np.expand_dims(img2, axis=0)\n",
    "        \n",
    "        metadata = self.metadata[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        # Convert to tensor\n",
    "        img1 = torch.tensor(img1, dtype=torch.float32)\n",
    "        img2 = torch.tensor(img2, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return img1, img2, metadata, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairs (e.g., first and second file are paired)\n",
    "image_pairs = [(nifti_images[i], nifti_images[i + 1]) for i in range(0, len(nifti_images) - 1, 2)]\n",
    "labels = None #Fill in correct path. response, PFS, and OS\n",
    "\n",
    "# Create dataset        Change resize!!!!!!!!!!!!!!\n",
    "train_dataset = PairedMedicalDataset(image_pairs, labels, transform=[ScaleIntensity(), EnsureChannelFirst(), Resize((96, 96, 96))])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(,8),      #8 classes (Path. resp. 2, PFS 3, OS 3)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, image1, image2, metadata):\n",
    "        # Pass both inputs through the shared model\n",
    "        output1 = self.base_model(image1)\n",
    "        output2 = self.base_model(image2)\n",
    "        #flatten image output\n",
    "        combined_embeddings = torch.cat((output1, output2, metadata), dim=1)\n",
    "        output3 = self.classifier(combined_embeddings)\n",
    "        return output3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spleen_ct_segmentation', '0.5.9'), ('pancreas_ct_dints_segmentation', '0.5.0'), ('brats_mri_segmentation', '0.5.3'), ('spleen_deepedit_annotation', '0.5.6'), ('swin_unetr_btcv_segmentation', '0.5.6'), ('ventricular_short_axis_3label', '0.3.3'), ('mednist_gan', '0.4.3'), ('pathology_tumor_detection', '0.6.2'), ('renalStructures_UNEST_segmentation', '0.2.5'), ('wholeBrainSeg_Large_UNEST_segmentation', '0.2.5'), ('prostate_mri_anatomy', '0.3.4'), ('valve_landmarks', '0.5.0'), ('lung_nodule_ct_detection', '0.6.9'), ('endoscopic_tool_segmentation', '0.6.1'), ('endoscopic_inbody_classification', '0.5.0'), ('breast_density_classification', '0.1.7'), ('mednist_reg', '0.0.6'), ('pathology_nuclei_classification', '0.2.0'), ('pathology_nuclick_annotation', '0.2.1'), ('pathology_nuclei_segmentation_classification', '0.2.6'), ('wholeBody_ct_segmentation', '0.2.5'), ('brats_mri_generative_diffusion', '1.1.3'), ('brats_mri_axial_slices_generative_diffusion', '1.1.3'), ('renalStructures_CECT_segmentation', '0.2.1'), ('multi_organ_segmentation', '0.0.5'), ('segmentation_template', '0.0.2'), ('classification_template', '0.0.3'), ('vista3d', '0.5.7'), ('maisi_ct_generative', '1.0.1'), ('vista2d', '0.3.0'), ('pediatric_abdominal_ct_segmentation', '0.4.4'), ('brain_image_synthesis_latent_diffusion_model', '1.0.2'), ('cxr_image_synthesis_latent_diffusion_model', '1.0.1'), ('mednist_ddpm', '1.0.2')]\n"
     ]
    }
   ],
   "source": [
    "import monai.bundle\n",
    "print(monai.bundle.get_all_bundles_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import monai\n",
    "import tqdm\n",
    "from monai.networks.nets import SwinUNETR\n",
    "\n",
    "pretrained_model = monai.bundle.load(\n",
    "    name=\"swin_unetr_btcv_segmentation\", bundle_dir=\"C:/Users/P095550/OneDrive - Amsterdam UMC/Documenten/GitHub/CRLM-morph-features/monai_whole_body_ct_model/monai_wholebody_ct_segmentation_0.2.5\"\n",
    ")\n",
    "\n",
    "\n",
    "# Define the network architecture\n",
    "network = SwinUNETR(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True\n",
    "    )\n",
    "\n",
    "# Load the pretrained weights into the network\n",
    "network.load_state_dict(pretrained_model)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv3d(1, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers1): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=48, out_features=48, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
      "            (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
      "            (fn): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layers2): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (fn): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layers3): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (fn): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layers4): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (fn): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = network.swinViT\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example input tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m)  \u001b[38;5;66;03m# Batch size 1, 1 channel, 96x96x96 image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\__init__.py:2784\u001b[0m\n\u001b[0;32m   2780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_DEVICE_BACKEND_AUTOLOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_device_backend_autoload_enabled():\n\u001b[1;32m-> 2784\u001b[0m     \u001b[43m_import_device_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_as_tensor_fullprec\u001b[39m(t):\n\u001b[0;32m   2788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;124;03m    Like torch.as_tensor, but when given Python data types it will keep\u001b[39;00m\n\u001b[0;32m   2790\u001b[0m \u001b[38;5;124;03m    them in full precision.  Used for calling convention for Dynamo.\u001b[39;00m\n\u001b[0;32m   2791\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\__init__.py:2751\u001b[0m, in \u001b[0;36m_import_device_backends\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2749\u001b[0m     backend_extensions \u001b[38;5;241m=\u001b[39m entry_points()\u001b[38;5;241m.\u001b[39mget(group_name, ())\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2751\u001b[0m     backend_extensions \u001b[38;5;241m=\u001b[39m \u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2753\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m backend_extension \u001b[38;5;129;01min\u001b[39;00m backend_extensions:\n\u001b[0;32m   2754\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2755\u001b[0m         \u001b[38;5;66;03m# Load the extension\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:971\u001b[0m, in \u001b[0;36mentry_points\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m    967\u001b[0m unique \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(unique_everseen, key\u001b[38;5;241m=\u001b[39mnorm_name)\n\u001b[0;32m    968\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m    969\u001b[0m     dist\u001b[38;5;241m.\u001b[39mentry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m unique(distributions())\n\u001b[0;32m    970\u001b[0m )\n\u001b[1;32m--> 971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSelectableGroups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:429\u001b[0m, in \u001b[0;36mSelectableGroups.load\u001b[1;34m(cls, eps)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, eps):\n\u001b[0;32m    428\u001b[0m     by_group \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 429\u001b[0m     ordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mgroupby(ordered, by_group)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m((group, EntryPoints(eps)) \u001b[38;5;28;01mfor\u001b[39;00m group, eps \u001b[38;5;129;01min\u001b[39;00m grouped)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:969\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    966\u001b[0m norm_name \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_normalized_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    967\u001b[0m unique \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(unique_everseen, key\u001b[38;5;241m=\u001b[39mnorm_name)\n\u001b[0;32m    968\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m--> 969\u001b[0m     \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m unique(distributions())\n\u001b[0;32m    970\u001b[0m )\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SelectableGroups\u001b[38;5;241m.\u001b[39mload(eps)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:601\u001b[0m, in \u001b[0;36mDistribution.entry_points\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints\u001b[38;5;241m.\u001b[39m_from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentry_points.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py:889\u001b[0m, in \u001b[0;36mPathDistribution.read_text\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[0;32m    884\u001b[0m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m     ):\n\u001b[1;32m--> 889\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:1132\u001b[0m, in \u001b[0;36mPath.read_text\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:1117\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1116\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    byte sequences.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    310\u001b[0m         IncrementalDecoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example input tensor\n",
    "input_tensor = torch.randn(1, 1, 96, 96, 96)  # Batch size 1, 1 channel, 96x96x96 image\n",
    "\n",
    "# Pass the input through the encoder\n",
    "features = encoder(input_tensor)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['dints_space.cell_tree.(0, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 0).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 1).preprocess.conv.weight', 'dints_space.cell_tree.(0, 1).preprocess.norm.weight', 'dints_space.cell_tree.(0, 1).preprocess.norm.bias', 'dints_space.cell_tree.(0, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(0, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(0, 2).preprocess.norm.weight', 'dints_space.cell_tree.(0, 2).preprocess.norm.bias', 'dints_space.cell_tree.(0, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 3).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 4).preprocess.conv.weight', 'dints_space.cell_tree.(0, 4).preprocess.norm.weight', 'dints_space.cell_tree.(0, 4).preprocess.norm.bias', 'dints_space.cell_tree.(0, 4).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 4).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 4).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 4).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(0, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(0, 5).preprocess.norm.weight', 'dints_space.cell_tree.(0, 5).preprocess.norm.bias', 'dints_space.cell_tree.(0, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 5).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 7).preprocess.conv.weight', 'dints_space.cell_tree.(0, 7).preprocess.norm.weight', 'dints_space.cell_tree.(0, 7).preprocess.norm.bias', 'dints_space.cell_tree.(0, 7).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 7).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(0, 7).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 7).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(0, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(0, 8).preprocess.norm.weight', 'dints_space.cell_tree.(0, 8).preprocess.norm.bias', 'dints_space.cell_tree.(0, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(0, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(0, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(0, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 1).preprocess.conv.weight', 'dints_space.cell_tree.(1, 1).preprocess.norm.weight', 'dints_space.cell_tree.(1, 1).preprocess.norm.bias', 'dints_space.cell_tree.(1, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(1, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(1, 2).preprocess.norm.weight', 'dints_space.cell_tree.(1, 2).preprocess.norm.bias', 'dints_space.cell_tree.(1, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(1, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(1, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(1, 5).preprocess.norm.weight', 'dints_space.cell_tree.(1, 5).preprocess.norm.bias', 'dints_space.cell_tree.(1, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 5).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(1, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 6).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(1, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 7).preprocess.conv.weight', 'dints_space.cell_tree.(1, 7).preprocess.norm.weight', 'dints_space.cell_tree.(1, 7).preprocess.norm.bias', 'dints_space.cell_tree.(1, 7).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 7).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(1, 7).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 7).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(1, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(1, 8).preprocess.norm.weight', 'dints_space.cell_tree.(1, 8).preprocess.norm.bias', 'dints_space.cell_tree.(1, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 8).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(1, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(1, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(1, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(1, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(2, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(2, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(2, 2).preprocess.norm.weight', 'dints_space.cell_tree.(2, 2).preprocess.norm.bias', 'dints_space.cell_tree.(2, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(2, 3).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(2, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(2, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(2, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(2, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(2, 5).preprocess.norm.weight', 'dints_space.cell_tree.(2, 5).preprocess.norm.bias', 'dints_space.cell_tree.(2, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(2, 5).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(2, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(2, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(2, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(2, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(2, 8).preprocess.norm.weight', 'dints_space.cell_tree.(2, 8).preprocess.norm.bias', 'dints_space.cell_tree.(2, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(2, 8).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(2, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(2, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(2, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(2, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(2, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(3, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(3, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(3, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(3, 1).preprocess.conv.weight', 'dints_space.cell_tree.(3, 1).preprocess.norm.weight', 'dints_space.cell_tree.(3, 1).preprocess.norm.bias', 'dints_space.cell_tree.(3, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(3, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(3, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(3, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(3, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(3, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(3, 2).preprocess.norm.weight', 'dints_space.cell_tree.(3, 2).preprocess.norm.bias', 'dints_space.cell_tree.(3, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(3, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(3, 5).preprocess.norm.weight', 'dints_space.cell_tree.(3, 5).preprocess.norm.bias', 'dints_space.cell_tree.(3, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(3, 6).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(3, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(3, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(3, 7).preprocess.conv.weight', 'dints_space.cell_tree.(3, 7).preprocess.norm.weight', 'dints_space.cell_tree.(3, 7).preprocess.norm.bias', 'dints_space.cell_tree.(3, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(3, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(3, 8).preprocess.norm.weight', 'dints_space.cell_tree.(3, 8).preprocess.norm.bias', 'dints_space.cell_tree.(3, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(3, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(3, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 1).preprocess.conv.weight', 'dints_space.cell_tree.(4, 1).preprocess.norm.weight', 'dints_space.cell_tree.(4, 1).preprocess.norm.bias', 'dints_space.cell_tree.(4, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(4, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(4, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(4, 2).preprocess.norm.weight', 'dints_space.cell_tree.(4, 2).preprocess.norm.bias', 'dints_space.cell_tree.(4, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(4, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 3).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(4, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(4, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(4, 5).preprocess.norm.weight', 'dints_space.cell_tree.(4, 5).preprocess.norm.bias', 'dints_space.cell_tree.(4, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 5).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(4, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(4, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(4, 8).preprocess.norm.weight', 'dints_space.cell_tree.(4, 8).preprocess.norm.bias', 'dints_space.cell_tree.(4, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 8).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(4, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(4, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(4, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(4, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(5, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(5, 2).preprocess.norm.weight', 'dints_space.cell_tree.(5, 2).preprocess.norm.bias', 'dints_space.cell_tree.(5, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(5, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 3).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(5, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 4).preprocess.conv.weight', 'dints_space.cell_tree.(5, 4).preprocess.norm.weight', 'dints_space.cell_tree.(5, 4).preprocess.norm.bias', 'dints_space.cell_tree.(5, 4).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 4).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(5, 4).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 4).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 7).preprocess.conv.weight', 'dints_space.cell_tree.(5, 7).preprocess.norm.weight', 'dints_space.cell_tree.(5, 7).preprocess.norm.bias', 'dints_space.cell_tree.(5, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(5, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(5, 8).preprocess.norm.weight', 'dints_space.cell_tree.(5, 8).preprocess.norm.bias', 'dints_space.cell_tree.(5, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(5, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(5, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(5, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 1).preprocess.conv.weight', 'dints_space.cell_tree.(6, 1).preprocess.norm.weight', 'dints_space.cell_tree.(6, 1).preprocess.norm.bias', 'dints_space.cell_tree.(6, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(6, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(6, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(6, 2).preprocess.norm.weight', 'dints_space.cell_tree.(6, 2).preprocess.norm.bias', 'dints_space.cell_tree.(6, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(6, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(6, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(6, 5).preprocess.norm.weight', 'dints_space.cell_tree.(6, 5).preprocess.norm.bias', 'dints_space.cell_tree.(6, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 6).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(6, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 7).preprocess.conv.weight', 'dints_space.cell_tree.(6, 7).preprocess.norm.weight', 'dints_space.cell_tree.(6, 7).preprocess.norm.bias', 'dints_space.cell_tree.(6, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(6, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(6, 8).preprocess.norm.weight', 'dints_space.cell_tree.(6, 8).preprocess.norm.bias', 'dints_space.cell_tree.(6, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(6, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(6, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(6, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 1).preprocess.conv.weight', 'dints_space.cell_tree.(7, 1).preprocess.norm.weight', 'dints_space.cell_tree.(7, 1).preprocess.norm.bias', 'dints_space.cell_tree.(7, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(7, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(7, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(7, 2).preprocess.norm.weight', 'dints_space.cell_tree.(7, 2).preprocess.norm.bias', 'dints_space.cell_tree.(7, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(7, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(7, 5).preprocess.norm.weight', 'dints_space.cell_tree.(7, 5).preprocess.norm.bias', 'dints_space.cell_tree.(7, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 7).preprocess.conv.weight', 'dints_space.cell_tree.(7, 7).preprocess.norm.weight', 'dints_space.cell_tree.(7, 7).preprocess.norm.bias', 'dints_space.cell_tree.(7, 7).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 7).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(7, 7).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 7).op.ops.0.norm.bias', 'dints_space.cell_tree.(7, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(7, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(7, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 1).preprocess.conv.weight', 'dints_space.cell_tree.(8, 1).preprocess.norm.weight', 'dints_space.cell_tree.(8, 1).preprocess.norm.bias', 'dints_space.cell_tree.(8, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 1).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(8, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(8, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(8, 2).preprocess.norm.weight', 'dints_space.cell_tree.(8, 2).preprocess.norm.bias', 'dints_space.cell_tree.(8, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(8, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 3).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 3).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(8, 3).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 3).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 5).preprocess.conv_1.weight', 'dints_space.cell_tree.(8, 5).preprocess.conv_2.weight', 'dints_space.cell_tree.(8, 5).preprocess.norm.weight', 'dints_space.cell_tree.(8, 5).preprocess.norm.bias', 'dints_space.cell_tree.(8, 5).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 5).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(8, 5).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 5).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 7).preprocess.conv.weight', 'dints_space.cell_tree.(8, 7).preprocess.norm.weight', 'dints_space.cell_tree.(8, 7).preprocess.norm.bias', 'dints_space.cell_tree.(8, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(8, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(8, 8).preprocess.norm.weight', 'dints_space.cell_tree.(8, 8).preprocess.norm.bias', 'dints_space.cell_tree.(8, 8).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 8).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 8).op.ops.0.norm.bias', 'dints_space.cell_tree.(8, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(8, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(8, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(9, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(9, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(9, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(9, 1).preprocess.conv.weight', 'dints_space.cell_tree.(9, 1).preprocess.norm.weight', 'dints_space.cell_tree.(9, 1).preprocess.norm.bias', 'dints_space.cell_tree.(9, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(9, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(9, 2).preprocess.norm.weight', 'dints_space.cell_tree.(9, 2).preprocess.norm.bias', 'dints_space.cell_tree.(9, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(9, 2).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(9, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(9, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(9, 4).preprocess.conv.weight', 'dints_space.cell_tree.(9, 4).preprocess.norm.weight', 'dints_space.cell_tree.(9, 4).preprocess.norm.bias', 'dints_space.cell_tree.(9, 4).op.ops.0.conv.weight', 'dints_space.cell_tree.(9, 4).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(9, 4).op.ops.0.norm.weight', 'dints_space.cell_tree.(9, 4).op.ops.0.norm.bias', 'dints_space.cell_tree.(9, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(9, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(9, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(9, 8).preprocess.conv_1.weight', 'dints_space.cell_tree.(9, 8).preprocess.conv_2.weight', 'dints_space.cell_tree.(9, 8).preprocess.norm.weight', 'dints_space.cell_tree.(9, 8).preprocess.norm.bias', 'dints_space.cell_tree.(9, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(9, 9).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(9, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(9, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(10, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(10, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(10, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(10, 1).preprocess.conv.weight', 'dints_space.cell_tree.(10, 1).preprocess.norm.weight', 'dints_space.cell_tree.(10, 1).preprocess.norm.bias', 'dints_space.cell_tree.(10, 2).preprocess.conv_1.weight', 'dints_space.cell_tree.(10, 2).preprocess.conv_2.weight', 'dints_space.cell_tree.(10, 2).preprocess.norm.weight', 'dints_space.cell_tree.(10, 2).preprocess.norm.bias', 'dints_space.cell_tree.(10, 2).op.ops.0.conv.weight', 'dints_space.cell_tree.(10, 2).op.ops.0.norm.weight', 'dints_space.cell_tree.(10, 2).op.ops.0.norm.bias', 'dints_space.cell_tree.(10, 6).op.ops.0.conv.weight', 'dints_space.cell_tree.(10, 6).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(10, 6).op.ops.0.norm.weight', 'dints_space.cell_tree.(10, 6).op.ops.0.norm.bias', 'dints_space.cell_tree.(10, 7).preprocess.conv.weight', 'dints_space.cell_tree.(10, 7).preprocess.norm.weight', 'dints_space.cell_tree.(10, 7).preprocess.norm.bias', 'dints_space.cell_tree.(10, 7).op.ops.0.conv.weight', 'dints_space.cell_tree.(10, 7).op.ops.0.norm.weight', 'dints_space.cell_tree.(10, 7).op.ops.0.norm.bias', 'dints_space.cell_tree.(10, 9).op.ops.0.conv.weight', 'dints_space.cell_tree.(10, 9).op.ops.0.norm.weight', 'dints_space.cell_tree.(10, 9).op.ops.0.norm.bias', 'dints_space.cell_tree.(11, 0).op.ops.0.conv.weight', 'dints_space.cell_tree.(11, 0).op.ops.0.conv_1.weight', 'dints_space.cell_tree.(11, 0).op.ops.0.norm.weight', 'dints_space.cell_tree.(11, 0).op.ops.0.norm.bias', 'dints_space.cell_tree.(11, 1).preprocess.conv.weight', 'dints_space.cell_tree.(11, 1).preprocess.norm.weight', 'dints_space.cell_tree.(11, 1).preprocess.norm.bias', 'dints_space.cell_tree.(11, 1).op.ops.0.conv.weight', 'dints_space.cell_tree.(11, 1).op.ops.0.norm.weight', 'dints_space.cell_tree.(11, 1).op.ops.0.norm.bias', 'dints_space.cell_tree.(11, 7).preprocess.conv.weight', 'dints_space.cell_tree.(11, 7).preprocess.norm.weight', 'dints_space.cell_tree.(11, 7).preprocess.norm.bias', 'stem_down.0.mod.1.weight', 'stem_down.0.mod.2.weight', 'stem_down.0.mod.2.bias', 'stem_down.0.mod.4.weight', 'stem_down.0.mod.5.weight', 'stem_down.0.mod.5.bias', 'stem_down.1.mod.1.weight', 'stem_down.1.mod.2.weight', 'stem_down.1.mod.2.bias', 'stem_down.1.mod.4.weight', 'stem_down.1.mod.5.weight', 'stem_down.1.mod.5.bias', 'stem_down.2.mod.1.weight', 'stem_down.2.mod.2.weight', 'stem_down.2.mod.2.bias', 'stem_down.2.mod.4.weight', 'stem_down.2.mod.5.weight', 'stem_down.2.mod.5.bias', 'stem_down.3.mod.1.weight', 'stem_down.3.mod.2.weight', 'stem_down.3.mod.2.bias', 'stem_down.3.mod.4.weight', 'stem_down.3.mod.5.weight', 'stem_down.3.mod.5.bias', 'stem_up.0.mod.1.weight', 'stem_up.0.mod.2.weight', 'stem_up.0.mod.2.bias', 'stem_up.1.mod.1.weight', 'stem_up.1.mod.2.weight', 'stem_up.1.mod.2.bias', 'stem_up.2.mod.1.weight', 'stem_up.2.mod.2.weight', 'stem_up.2.mod.2.bias', 'stem_up.3.mod.1.weight', 'stem_up.3.mod.2.weight', 'stem_up.3.mod.2.bias', 'stem_finals.0.conv.weight', 'stem_finals.0.norm.weight', 'stem_finals.0.norm.bias', 'stem_finals.1.weight', 'stem_finals.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Step 2: Load the saved state dictionary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/P095550/OneDrive - Amsterdam UMC/Documenten/GitHub/CRLM-morph-features/monai_whole_body_ct_model/monai_wholebody_ct_segmentation_0.2.5/_/models/model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m network \u001b[38;5;241m=\u001b[39m SegResNet(\n\u001b[0;32m      9\u001b[0m     spatial_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 3: Load the weights into the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1463\u001b[0m             opened_zipfile,\n\u001b[0;32m   1464\u001b[0m             map_location,\n\u001b[0;32m   1465\u001b[0m             _weights_only_unpickler,\n\u001b[0;32m   1466\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1467\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1468\u001b[0m         )\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     ):\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[0;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         )\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[0;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1903\u001b[0m )\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:631\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    629\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 631\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\serialization.py:600\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    598\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    608\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import SegResNet\n",
    "map_location=torch.device('cpu')\n",
    "\n",
    "# Step 2: Load the saved state dictionary\n",
    "model_path = \"C:/Users/P095550/OneDrive - Amsterdam UMC/Documenten/GitHub/CRLM-morph-features/monai_whole_body_ct_model/monai_wholebody_ct_segmentation_0.2.5/_/models/model.pt\"\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "network = SegResNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=105,\n",
    "    init_filters=32,\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "# Step 3: Load the weights into the model\n",
    "network.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SegResNet\n",
    "\"\"\"\n",
    "\"network_def\": {\n",
    "        \"_target_\": \"SegResNet\",\n",
    "        \"spatial_dims\": 3,\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 105,\n",
    "        \"init_filters\": 32,\n",
    "        \"blocks_down\": [\n",
    "            1,\n",
    "            2,\n",
    "            2,\n",
    "            4\n",
    "        ],\n",
    "        \"blocks_up\": [\n",
    "            1,\n",
    "            1,\n",
    "            1\n",
    "        ],\n",
    "        \"dropout_prob\": 0.2\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "network = SegResNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=105,\n",
    "    init_filters=32,\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "network.load_statedict(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
