{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import SiameseNetwork, PairedMedicalDataset\n",
    "import shap\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    "    Compose\n",
    ")\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\P095550/.cache\\torch\\hub\\Warvito_MedicalNet-models_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (base_model): Sequential(\n",
       "    (0): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=518, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the base model (e.g., ResNet or other feature extractor)\n",
    "\n",
    "resnet_model = torch.hub.load('Warvito/MedicalNet-models', 'medicalnet_resnet10')\n",
    "\n",
    "# Remove the final classification layer (fc) to keep only the encoder part\n",
    "encoder = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "\n",
    "model = SiameseNetwork(encoder)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SiameseWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        image1, image2, metadata = input\n",
    "        return self.model(image1, image2, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_dir = \"L:/Basic/divi/jstoker/slicer_pdac/Master Students WS 24/Martijn/data/Training/paired_scans\"\n",
    "clinical_data_dir = \"C:/Users/P095550/OneDrive - Amsterdam UMC/Documenten/GitHub/CRLM-morph-features\"\n",
    "nifti_images = sorted(glob.glob(os.path.join(data_dir, \"*.nii.gz\")))   \n",
    "\n",
    "# Create pairs (e.g., first and second file are paired)\n",
    "image_pairs = [(nifti_images[i], nifti_images[i + 1]) for i in range(0, len(nifti_images) - 1, 2)]\n",
    "\n",
    "pd_metadata = pd.read_csv(os.path.join(clinical_data_dir, \"training_input.csv\"))\n",
    "all_metadata = torch.tensor(pd_metadata.values.tolist())\n",
    "\n",
    "pd_labels = pd.read_csv(os.path.join(clinical_data_dir, \"training_labels.csv\"))\n",
    "all_labels = torch.tensor(pd_labels.values.tolist()) #Fill in correct path. response, PFS, and OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = PairedMedicalDataset(\n",
    "    image_pairs, all_metadata, all_labels, transform=[ScaleIntensity(), Resize((64, 256, 256), mode=\"trilinear\")]\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=11, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "# Create an iterator for the DataLoader\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "# Extract one batch\n",
    "batch = next(data_iter)\n",
    "\n",
    "# Unpack the batch (if applicable)\n",
    "img1, img2, metadata, labels = batch\n",
    "\n",
    "\n",
    "# Dummy image pair input\n",
    "image1_test = img1[0].to(\"cuda\")\n",
    "image2_test = img2[0].to(\"cuda\")\n",
    "metadata_test = metadata[0].to(\"cuda\")\n",
    "\n",
    "\n",
    "# Background for SHAP (used by DeepExplainer)\n",
    "image1_bg = img1[1:].to(\"cuda\")\n",
    "image2_bg = img2[1:].to(\"cuda\")\n",
    "metadata_bg = metadata[1:].to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'monai.data.meta_tensor.MetaTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(image2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrapped_model = SiameseWrapper(model).to(\"cuda\")\n",
    "\n",
    "# Use DeepExplainer for PyTorch models\n",
    "explainer = shap.GradientExplainer(\n",
    "    wrapped_model,\n",
    "    data=(image1_bg, image2_bg, metadata_bg)\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values((image1_test, image2_test, metadata_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
