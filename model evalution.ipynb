{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SiameseNetwork_Images' from 'models' (c:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SiameseNetwork_Images, SiameseNetwork_Full, PairedMedicalDataset_Images, PairedMedicalDataset_Full\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SiameseNetwork_Images' from 'models' (c:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\models.py)"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import SiameseNetwork_Images, SiameseNetwork_Full, PairedMedicalDataset_Images, PairedMedicalDataset_Full\n",
    "import shap\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    "    Compose\n",
    ")\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the base model (e.g., ResNet or other feature extractor)\n",
    "\n",
    "resnet_model = torch.hub.load('Warvito/MedicalNet-models', 'medicalnet_resnet10')\n",
    "\n",
    "# Remove the final classification layer (fc) to keep only the encoder part\n",
    "encoder = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "\n",
    "model = SiameseNetwork(encoder)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the base model (e.g., ResNet or other feature extractor)\n",
    "\n",
    "resnet_model = torch.hub.load('Warvito/MedicalNet-models', 'medicalnet_resnet10')\n",
    "\n",
    "# Remove the final classification layer (fc) to keep only the encoder part\n",
    "encoder = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "\n",
    "model = SiameseNetwork(encoder)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SiameseWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        image1, image2, metadata = input\n",
    "        return self.model(image1, image2, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_dir = \"L:/Basic/divi/jstoker/slicer_pdac/Master Students WS 24/Martijn/data/Training/paired_scans\"\n",
    "clinical_data_dir = \"C:/Users/P095550/OneDrive - Amsterdam UMC/Documenten/GitHub/CRLM-morph-features\"\n",
    "nifti_images = sorted(glob.glob(os.path.join(data_dir, \"*.nii.gz\")))   \n",
    "\n",
    "# Create pairs (e.g., first and second file are paired)\n",
    "image_pairs = [(nifti_images[i], nifti_images[i + 1]) for i in range(0, len(nifti_images) - 1, 2)]\n",
    "\n",
    "pd_metadata = pd.read_csv(os.path.join(clinical_data_dir, \"training_input.csv\"))\n",
    "all_metadata = torch.tensor(pd_metadata.values.tolist())\n",
    "\n",
    "pd_labels = pd.read_csv(os.path.join(clinical_data_dir, \"training_labels.csv\"))\n",
    "all_labels = torch.tensor(pd_labels.values.tolist()) #Fill in correct path. response, PFS, and OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PairedMedicalDataset(\n",
    "    image_pairs, all_metadata, all_labels, transform=[ScaleIntensity(), Resize((64, 256, 256), mode=\"trilinear\")]\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor([[0.4648, 0.5368, 0.4234, 0.7841, 0.5976, 0.5243, 0.7695, 0.5624, 0.5321]])\n",
      "metatensor([[0.5212, 0.5548, 0.4162, 0.7993, 0.6100, 0.4530, 0.7992, 0.5509, 0.4867]])\n",
      "metatensor([[0.4251, 0.2870, 0.2183, 0.9963, 0.9055, 0.6109, 0.9938, 0.8718, 0.9511]])\n",
      "metatensor([[0.4378, 0.4328, 0.5289, 0.8097, 0.6394, 0.6598, 0.8072, 0.6486, 0.6172]])\n",
      "metatensor([[0.4190, 0.2747, 0.2222, 0.9965, 0.9095, 0.6159, 0.9941, 0.8803, 0.9549]])\n",
      "metatensor([[0.4574, 0.5144, 0.4293, 0.7928, 0.5997, 0.5310, 0.7726, 0.5715, 0.5349]])\n",
      "metatensor([[0.4685, 0.5515, 0.4179, 0.7783, 0.6079, 0.5294, 0.7706, 0.5585, 0.5298]])\n",
      "metatensor([[0.4930, 0.5665, 0.3967, 0.7840, 0.5926, 0.4583, 0.7767, 0.5344, 0.4833]])\n",
      "metatensor([[0.5485, 0.5451, 0.4688, 0.8128, 0.6254, 0.4677, 0.8322, 0.5704, 0.4864]])\n",
      "metatensor([[0.4905, 0.5431, 0.2512, 0.9462, 0.7551, 0.5013, 0.9299, 0.6360, 0.7539]])\n",
      "metatensor([[0.4671, 0.5513, 0.3740, 0.7870, 0.5925, 0.4820, 0.7645, 0.5478, 0.5285]])\n",
      "metatensor([[0.5551, 0.5530, 0.4977, 0.8184, 0.6199, 0.4864, 0.8450, 0.5808, 0.4808]])\n",
      "metatensor([[0.3382, 0.1846, 0.8106, 0.9480, 0.7017, 0.8621, 0.9438, 0.8837, 0.8354]])\n",
      "metatensor([[0.4980, 0.5581, 0.4131, 0.7875, 0.6003, 0.4693, 0.7825, 0.5455, 0.4884]])\n",
      "metatensor([[0.5220, 0.5058, 0.5096, 0.8173, 0.6167, 0.5621, 0.8363, 0.5977, 0.5083]])\n",
      "metatensor([[0.5721, 0.5097, 0.5677, 0.8344, 0.6426, 0.5544, 0.8780, 0.6172, 0.4933]])\n",
      "metatensor([[0.5009, 0.5572, 0.4335, 0.7844, 0.5894, 0.4827, 0.7887, 0.5407, 0.4808]])\n",
      "metatensor([[0.4761, 0.5493, 0.4224, 0.7736, 0.5890, 0.4966, 0.7631, 0.5410, 0.4938]])\n",
      "metatensor([[0.3345, 0.1881, 0.8132, 0.9449, 0.6908, 0.8713, 0.9418, 0.8779, 0.8230]])\n",
      "metatensor([[0.4903, 0.5757, 0.3643, 0.7865, 0.5893, 0.4499, 0.7762, 0.5342, 0.4997]])\n",
      "metatensor([[0.4662, 0.5389, 0.4044, 0.7918, 0.6180, 0.5272, 0.7796, 0.5640, 0.5708]])\n",
      "metatensor([[0.4668, 0.5480, 0.4125, 0.7784, 0.6005, 0.5225, 0.7670, 0.5539, 0.5283]])\n",
      "metatensor([[0.5052, 0.5885, 0.3573, 0.7904, 0.5870, 0.4269, 0.7793, 0.5457, 0.4959]])\n",
      "metatensor([[0.4805, 0.5522, 0.4404, 0.7738, 0.6011, 0.5284, 0.7771, 0.5594, 0.5229]])\n",
      "metatensor([[0.4178, 0.4053, 0.5381, 0.8459, 0.6537, 0.6905, 0.8299, 0.6969, 0.6928]])\n",
      "metatensor([[0.5402, 0.5499, 0.4671, 0.8114, 0.6188, 0.4703, 0.8234, 0.5600, 0.4835]])\n",
      "metatensor([[0.4506, 0.5035, 0.4547, 0.7907, 0.6270, 0.5907, 0.7845, 0.6015, 0.6013]])\n",
      "metatensor([[0.4830, 0.5506, 0.4155, 0.7815, 0.5946, 0.4791, 0.7733, 0.5402, 0.4899]])\n",
      "metatensor([[0.4855, 0.5373, 0.4776, 0.7825, 0.6053, 0.5374, 0.7902, 0.5578, 0.4957]])\n",
      "metatensor([[0.5090, 0.6201, 0.2341, 0.8817, 0.6446, 0.4103, 0.8516, 0.5210, 0.5919]])\n",
      "metatensor([[0.3443, 0.2480, 0.6073, 0.9483, 0.7416, 0.7148, 0.9251, 0.8456, 0.8606]])\n",
      "metatensor([[0.4978, 0.5731, 0.3072, 0.8550, 0.6492, 0.4818, 0.8407, 0.5213, 0.5953]])\n",
      "metatensor([[0.4988, 0.5755, 0.3794, 0.7867, 0.5942, 0.4401, 0.7813, 0.5354, 0.4912]])\n",
      "metatensor([[0.3928, 0.3407, 0.4773, 0.9225, 0.7475, 0.6272, 0.8930, 0.7616, 0.8087]])\n",
      "metatensor([[0.4729, 0.5515, 0.4235, 0.7871, 0.5988, 0.5238, 0.7827, 0.5599, 0.5428]])\n",
      "metatensor([[0.5068, 0.6112, 0.2397, 0.8865, 0.6589, 0.4322, 0.8573, 0.5298, 0.6103]])\n",
      "metatensor([[0.4028, 0.3531, 0.5896, 0.8650, 0.6615, 0.7256, 0.8440, 0.7369, 0.7183]])\n",
      "metatensor([[0.4727, 0.5308, 0.4405, 0.7913, 0.6003, 0.5330, 0.7865, 0.5614, 0.5117]])\n",
      "metatensor([[0.4873, 0.5845, 0.3192, 0.7986, 0.5916, 0.4282, 0.7714, 0.5274, 0.5087]])\n",
      "metatensor([[0.4987, 0.6397, 0.2063, 0.8780, 0.6274, 0.3678, 0.8442, 0.4873, 0.5365]])\n",
      "metatensor([[0.3840, 0.3126, 0.5695, 0.9066, 0.7005, 0.6921, 0.8804, 0.7817, 0.7961]])\n",
      "metatensor([[0.4958, 0.5865, 0.2842, 0.8566, 0.6352, 0.4555, 0.8278, 0.5177, 0.5773]])\n",
      "metatensor([[0.5003, 0.5906, 0.3223, 0.7978, 0.6001, 0.4186, 0.7862, 0.5292, 0.5075]])\n",
      "metatensor([[0.4358, 0.4604, 0.5002, 0.7981, 0.6307, 0.6395, 0.7913, 0.6279, 0.6209]])\n",
      "metatensor([[0.4718, 0.5635, 0.3708, 0.8017, 0.5984, 0.4821, 0.7830, 0.5514, 0.5437]])\n",
      "metatensor([[0.5539, 0.5358, 0.5176, 0.8197, 0.6360, 0.5048, 0.8548, 0.5855, 0.4764]])\n",
      "metatensor([[0.3621, 0.2647, 0.5349, 0.9543, 0.7708, 0.6796, 0.9343, 0.8280, 0.8668]])\n",
      "metatensor([[0.5369, 0.7536, 0.0914, 0.9745, 0.7490, 0.3208, 0.9568, 0.5640, 0.7036]])\n",
      "metatensor([[0.4274, 0.4052, 0.4411, 0.9078, 0.7192, 0.6071, 0.8822, 0.6984, 0.7623]])\n",
      "metatensor([[0.4331, 0.3031, 0.2302, 0.9948, 0.8944, 0.5984, 0.9919, 0.8550, 0.9421]])\n",
      "metatensor([[0.4585, 0.5206, 0.4387, 0.7843, 0.6034, 0.5431, 0.7712, 0.5614, 0.5241]])\n",
      "metatensor([[0.4535, 0.4446, 0.3185, 0.9468, 0.7743, 0.5466, 0.9300, 0.7020, 0.7932]])\n",
      "metatensor([[0.4659, 0.5438, 0.3518, 0.8262, 0.6209, 0.4892, 0.7959, 0.5536, 0.5813]])\n",
      "metatensor([[0.4681, 0.5505, 0.3771, 0.7905, 0.5951, 0.4893, 0.7697, 0.5568, 0.5418]])\n",
      "metatensor([[0.4793, 0.5571, 0.3861, 0.8045, 0.5999, 0.5105, 0.7928, 0.5465, 0.5473]])\n",
      "metatensor([[0.5129, 0.6069, 0.2317, 0.9172, 0.7005, 0.4490, 0.9016, 0.5546, 0.6701]])\n",
      "metatensor([[0.4604, 0.5229, 0.4076, 0.8090, 0.6401, 0.5511, 0.7922, 0.5785, 0.6110]])\n",
      "metatensor([[0.4199, 0.3787, 0.4300, 0.9148, 0.7363, 0.5877, 0.8874, 0.7246, 0.7818]])\n",
      "metatensor([[0.4779, 0.5169, 0.4800, 0.7887, 0.5966, 0.5584, 0.7858, 0.5679, 0.4987]])\n",
      "metatensor([[0.5140, 0.7330, 0.1127, 0.9513, 0.6871, 0.2970, 0.9238, 0.5372, 0.6245]])\n",
      "metatensor([[0.4604, 0.5385, 0.4028, 0.7818, 0.6035, 0.5121, 0.7647, 0.5502, 0.5343]])\n",
      "metatensor([[0.4566, 0.4903, 0.4004, 0.8621, 0.6762, 0.5602, 0.8427, 0.6127, 0.6759]])\n",
      "metatensor([[0.3564, 0.2452, 0.7169, 0.9192, 0.6693, 0.8005, 0.9035, 0.8320, 0.7975]])\n",
      "metatensor([[0.4928, 0.5633, 0.4105, 0.7833, 0.5919, 0.4716, 0.7834, 0.5358, 0.4930]])\n",
      "metatensor([[0.4720, 0.5258, 0.3448, 0.8817, 0.6859, 0.5312, 0.8638, 0.5828, 0.6718]])\n",
      "metatensor([[0.4637, 0.5385, 0.4300, 0.7890, 0.6100, 0.5405, 0.7800, 0.5475, 0.5266]])\n",
      "metatensor([[0.4865, 0.5120, 0.5015, 0.8004, 0.6222, 0.5927, 0.8096, 0.5851, 0.5087]])\n",
      "metatensor([[0.4925, 0.4999, 0.4987, 0.8033, 0.6070, 0.5816, 0.8084, 0.5927, 0.5192]])\n",
      "metatensor([[0.4745, 0.5425, 0.4184, 0.7803, 0.5970, 0.5129, 0.7699, 0.5515, 0.5294]])\n",
      "metatensor([[0.4152, 0.3953, 0.5200, 0.8485, 0.6644, 0.6530, 0.8205, 0.7066, 0.7139]])\n",
      "metatensor([[0.4970, 0.5519, 0.4396, 0.7834, 0.5916, 0.4897, 0.7823, 0.5380, 0.4792]])\n",
      "metatensor([[0.5335, 0.5447, 0.4852, 0.7972, 0.6059, 0.4931, 0.8223, 0.5674, 0.4777]])\n",
      "metatensor([[0.5281, 0.5243, 0.4776, 0.8215, 0.6224, 0.5182, 0.8334, 0.5888, 0.5064]])\n",
      "metatensor([[0.4770, 0.5337, 0.4636, 0.7864, 0.5979, 0.5492, 0.7850, 0.5520, 0.5099]])\n",
      "metatensor([[0.5335, 0.4964, 0.5670, 0.8177, 0.6306, 0.6104, 0.8509, 0.6126, 0.5067]])\n",
      "metatensor([[0.4190, 0.3454, 0.3899, 0.9517, 0.7922, 0.5905, 0.9353, 0.7722, 0.8463]])\n",
      "metatensor([[0.4487, 0.4108, 0.3238, 0.9575, 0.7917, 0.5588, 0.9446, 0.7302, 0.8269]])\n",
      "metatensor([[0.4950, 0.6464, 0.1999, 0.8792, 0.6235, 0.3647, 0.8337, 0.4948, 0.5396]])\n",
      "metatensor([[0.4760, 0.5627, 0.3724, 0.7951, 0.5878, 0.4694, 0.7796, 0.5374, 0.5111]])\n",
      "metatensor([[0.4689, 0.5352, 0.4420, 0.7879, 0.6032, 0.5395, 0.7833, 0.5499, 0.5211]])\n",
      "metatensor([[0.4938, 0.5421, 0.4899, 0.7818, 0.6036, 0.5489, 0.7935, 0.5617, 0.4960]])\n",
      "metatensor([[0.4960, 0.5529, 0.4392, 0.7785, 0.5906, 0.4823, 0.7794, 0.5379, 0.4810]])\n",
      "metatensor([[0.3887, 0.3130, 0.6493, 0.8658, 0.6535, 0.7600, 0.8498, 0.7528, 0.7149]])\n",
      "metatensor([[0.5178, 0.7116, 0.1355, 0.9408, 0.6812, 0.3263, 0.9130, 0.5387, 0.6327]])\n",
      "metatensor([[0.3257, 0.1624, 0.8447, 0.9578, 0.7056, 0.8860, 0.9565, 0.9020, 0.8511]])\n",
      "metatensor([[0.4431, 0.4776, 0.4807, 0.8016, 0.6254, 0.6189, 0.7919, 0.6153, 0.6050]])\n",
      "metatensor([[0.4152, 0.3605, 0.4431, 0.9169, 0.7449, 0.5901, 0.8905, 0.7481, 0.7983]])\n",
      "metatensor([[0.4717, 0.5440, 0.3761, 0.8043, 0.6183, 0.5045, 0.7861, 0.5595, 0.5775]])\n",
      "metatensor([[0.5144, 0.5594, 0.4240, 0.7996, 0.6109, 0.4493, 0.7974, 0.5435, 0.4808]])\n",
      "metatensor([[0.5021, 0.5425, 0.4544, 0.8017, 0.6019, 0.5038, 0.8035, 0.5540, 0.4744]])\n",
      "metatensor([[0.4679, 0.5349, 0.4382, 0.7883, 0.5989, 0.5314, 0.7782, 0.5544, 0.5134]])\n",
      "metatensor([[0.3420, 0.2467, 0.6110, 0.9520, 0.7345, 0.7356, 0.9321, 0.8442, 0.8629]])\n",
      "metatensor([[0.4440, 0.4355, 0.4249, 0.9010, 0.7130, 0.5986, 0.8803, 0.6762, 0.7446]])\n",
      "metatensor([[0.5772, 0.5247, 0.5212, 0.8252, 0.6417, 0.5055, 0.8594, 0.5907, 0.5010]])\n",
      "metatensor([[0.5101, 0.5389, 0.4450, 0.7977, 0.6136, 0.4904, 0.8034, 0.5640, 0.4990]])\n",
      "metatensor([[0.4733, 0.5623, 0.3678, 0.7867, 0.5888, 0.4706, 0.7649, 0.5427, 0.5196]])\n",
      "metatensor([[0.4904, 0.5591, 0.3197, 0.8614, 0.6625, 0.5018, 0.8478, 0.5386, 0.6234]])\n",
      "metatensor([[0.4796, 0.5564, 0.3984, 0.7737, 0.5811, 0.4833, 0.7612, 0.5419, 0.5034]])\n",
      "metatensor([[0.6331, 0.4821, 0.5658, 0.8649, 0.6727, 0.5185, 0.9006, 0.6458, 0.5639]])\n",
      "metatensor([[0.4808, 0.5742, 0.3227, 0.8030, 0.5934, 0.4429, 0.7726, 0.5234, 0.5289]])\n",
      "metatensor([[0.3879, 0.2680, 0.7188, 0.8921, 0.6698, 0.8101, 0.8881, 0.7882, 0.7261]])\n",
      "metatensor([[0.4606, 0.4794, 0.3716, 0.8912, 0.7025, 0.5463, 0.8695, 0.6319, 0.7128]])\n",
      "metatensor([[0.4554, 0.5112, 0.4536, 0.7927, 0.6294, 0.5876, 0.7906, 0.5950, 0.6031]])\n",
      "metatensor([[0.5097, 0.5603, 0.4148, 0.8043, 0.6076, 0.4595, 0.8010, 0.5426, 0.4833]])\n",
      "metatensor([[0.4671, 0.5456, 0.4076, 0.7987, 0.6054, 0.5293, 0.7835, 0.5551, 0.5363]])\n",
      "metatensor([[0.4020, 0.3682, 0.5725, 0.8510, 0.6464, 0.7118, 0.8267, 0.7256, 0.7058]])\n",
      "metatensor([[0.4632, 0.5356, 0.4447, 0.7727, 0.6130, 0.5553, 0.7712, 0.5601, 0.5324]])\n",
      "metatensor([[0.5782, 0.4961, 0.5327, 0.8365, 0.6528, 0.5326, 0.8653, 0.6031, 0.5137]])\n",
      "metatensor([[0.4367, 0.4481, 0.4669, 0.8579, 0.6810, 0.6216, 0.8323, 0.6623, 0.6977]])\n",
      "metatensor([[0.4081, 0.3093, 0.4189, 0.9591, 0.8038, 0.6066, 0.9460, 0.8033, 0.8728]])\n",
      "metatensor([[0.4093, 0.3982, 0.5320, 0.8440, 0.6578, 0.6885, 0.8238, 0.6972, 0.6919]])\n",
      "metatensor([[0.4590, 0.5129, 0.4717, 0.7771, 0.6190, 0.5923, 0.7841, 0.5886, 0.5679]])\n",
      "metatensor([[0.4682, 0.5274, 0.4547, 0.7732, 0.6023, 0.5452, 0.7683, 0.5609, 0.5124]])\n",
      "metatensor([[0.4718, 0.5501, 0.3831, 0.7885, 0.6024, 0.4832, 0.7757, 0.5381, 0.5311]])\n",
      "metatensor([[0.4274, 0.4266, 0.4783, 0.8698, 0.6905, 0.6382, 0.8425, 0.6876, 0.7202]])\n",
      "metatensor([[0.5002, 0.6208, 0.2435, 0.8366, 0.6064, 0.3772, 0.7976, 0.5091, 0.5060]])\n",
      "metatensor([[0.4647, 0.5510, 0.3649, 0.8010, 0.5997, 0.4839, 0.7749, 0.5479, 0.5433]])\n",
      "metatensor([[0.5696, 0.5074, 0.5268, 0.8330, 0.6446, 0.5316, 0.8635, 0.6047, 0.5121]])\n",
      "metatensor([[0.4642, 0.5216, 0.4437, 0.7814, 0.6104, 0.5485, 0.7769, 0.5679, 0.5584]])\n",
      "metatensor([[0.4766, 0.5637, 0.3724, 0.7810, 0.5860, 0.4752, 0.7611, 0.5528, 0.5243]])\n",
      "metatensor([[0.4940, 0.5635, 0.3975, 0.7811, 0.5915, 0.4590, 0.7745, 0.5360, 0.4930]])\n",
      "metatensor([[0.4526, 0.4944, 0.4646, 0.7957, 0.6245, 0.5835, 0.7880, 0.5967, 0.5674]])\n",
      "metatensor([[0.5068, 0.5264, 0.4955, 0.8077, 0.6062, 0.5471, 0.8252, 0.5875, 0.4888]])\n",
      "metatensor([[0.4839, 0.4898, 0.1938, 0.9836, 0.8283, 0.5090, 0.9759, 0.7283, 0.8494]])\n",
      "metatensor([[0.3526, 0.2312, 0.7474, 0.9247, 0.6726, 0.8246, 0.9144, 0.8415, 0.7962]])\n",
      "metatensor([[0.6072, 0.5246, 0.5122, 0.8433, 0.6423, 0.4478, 0.8586, 0.5916, 0.5077]])\n",
      "metatensor([[0.4607, 0.5266, 0.4024, 0.7993, 0.6125, 0.5192, 0.7811, 0.5735, 0.5740]])\n",
      "metatensor([[0.4832, 0.5341, 0.4576, 0.7841, 0.5929, 0.5211, 0.7838, 0.5551, 0.4909]])\n",
      "metatensor([[0.5119, 0.5420, 0.4528, 0.7971, 0.6112, 0.4963, 0.8056, 0.5619, 0.4955]])\n",
      "metatensor([[0.5006, 0.5259, 0.4720, 0.7975, 0.6019, 0.5281, 0.8078, 0.5786, 0.4877]])\n",
      "metatensor([[0.3370, 0.2205, 0.6154, 0.9623, 0.7684, 0.7318, 0.9441, 0.8673, 0.8887]])\n",
      "metatensor([[0.5368, 0.5386, 0.4999, 0.8091, 0.6053, 0.5160, 0.8334, 0.5856, 0.4956]])\n",
      "metatensor([[0.4691, 0.5484, 0.3991, 0.7769, 0.5958, 0.5104, 0.7600, 0.5596, 0.5387]])\n",
      "metatensor([[0.4800, 0.5586, 0.3801, 0.8020, 0.6129, 0.5135, 0.8007, 0.5419, 0.5611]])\n",
      "metatensor([[0.4735, 0.5386, 0.4226, 0.7797, 0.5957, 0.5045, 0.7705, 0.5530, 0.5066]])\n",
      "metatensor([[0.3553, 0.2738, 0.6358, 0.9247, 0.6767, 0.7622, 0.8973, 0.8143, 0.8025]])\n",
      "metatensor([[0.3955, 0.3463, 0.5770, 0.8623, 0.6566, 0.6972, 0.8360, 0.7416, 0.7326]])\n",
      "metatensor([[0.4546, 0.5138, 0.4418, 0.7934, 0.6187, 0.5752, 0.7878, 0.5757, 0.5788]])\n",
      "metatensor([[0.4304, 0.3649, 0.3480, 0.9647, 0.8057, 0.5863, 0.9515, 0.7693, 0.8543]])\n",
      "metatensor([[0.4731, 0.5589, 0.3661, 0.7919, 0.5978, 0.4862, 0.7698, 0.5384, 0.5343]])\n",
      "metatensor([[0.4610, 0.5192, 0.4504, 0.7799, 0.6081, 0.5613, 0.7717, 0.5703, 0.5450]])\n",
      "metatensor([[0.4779, 0.5024, 0.2712, 0.9514, 0.7676, 0.5198, 0.9380, 0.6657, 0.7747]])\n",
      "metatensor([[0.4305, 0.4372, 0.4712, 0.8645, 0.6863, 0.6225, 0.8388, 0.6722, 0.7155]])\n",
      "metatensor([[0.4673, 0.5440, 0.4316, 0.7747, 0.6100, 0.5395, 0.7690, 0.5648, 0.5339]])\n",
      "metatensor([[0.4308, 0.3416, 0.6595, 0.8647, 0.6580, 0.7718, 0.8637, 0.7337, 0.6522]])\n",
      "metatensor([[0.4920, 0.5537, 0.4483, 0.7792, 0.5759, 0.5305, 0.7812, 0.5646, 0.5156]])\n",
      "metatensor([[0.5123, 0.6079, 0.3576, 0.7979, 0.5859, 0.3834, 0.7916, 0.5350, 0.4615]])\n",
      "metatensor([[0.5314, 0.5451, 0.4856, 0.8066, 0.6100, 0.5049, 0.8251, 0.5691, 0.4774]])\n",
      "metatensor([[0.5330, 0.5511, 0.4795, 0.8039, 0.6049, 0.4860, 0.8231, 0.5700, 0.4648]])\n",
      "metatensor([[0.3333, 0.2167, 0.7398, 0.9364, 0.6840, 0.8218, 0.9225, 0.8588, 0.8288]])\n",
      "metatensor([[0.4978, 0.5878, 0.3254, 0.8006, 0.6025, 0.4194, 0.7883, 0.5270, 0.4914]])\n",
      "metatensor([[0.3401, 0.1601, 0.8457, 0.9563, 0.7097, 0.8928, 0.9565, 0.8960, 0.8271]])\n",
      "metatensor([[0.5104, 0.6396, 0.2097, 0.8782, 0.6396, 0.3575, 0.8461, 0.4923, 0.5187]])\n",
      "metatensor([[0.4792, 0.5706, 0.3451, 0.7959, 0.5981, 0.4549, 0.7741, 0.5379, 0.5303]])\n",
      "metatensor([[0.4684, 0.5422, 0.4315, 0.7742, 0.6078, 0.5354, 0.7679, 0.5632, 0.5316]])\n",
      "metatensor([[0.4763, 0.5027, 0.4991, 0.8090, 0.6172, 0.6067, 0.8181, 0.5943, 0.5372]])\n",
      "metatensor([[0.4252, 0.4199, 0.4641, 0.8815, 0.7005, 0.6263, 0.8530, 0.6863, 0.7317]])\n",
      "metatensor([[0.4659, 0.5440, 0.3887, 0.7972, 0.6198, 0.5099, 0.7852, 0.5490, 0.5565]])\n",
      "metatensor([[0.5524, 0.5275, 0.4955, 0.8244, 0.6317, 0.5049, 0.8468, 0.5831, 0.4907]])\n",
      "metatensor([[0.4281, 0.3752, 0.3676, 0.9501, 0.7878, 0.5756, 0.9331, 0.7517, 0.8327]])\n",
      "metatensor([[0.4927, 0.5550, 0.3840, 0.7938, 0.6071, 0.4643, 0.7882, 0.5396, 0.5039]])\n",
      "metatensor([[0.4856, 0.5376, 0.4399, 0.7851, 0.6008, 0.5004, 0.7815, 0.5497, 0.4849]])\n",
      "metatensor([[0.4650, 0.5276, 0.4468, 0.7816, 0.6015, 0.5390, 0.7706, 0.5572, 0.5112]])\n",
      "metatensor([[0.5038, 0.6336, 0.2135, 0.8849, 0.6411, 0.3837, 0.8474, 0.5191, 0.5775]])\n",
      "metatensor([[0.4982, 0.6060, 0.2477, 0.8682, 0.6410, 0.4166, 0.8355, 0.5208, 0.5830]])\n",
      "metatensor([[0.3709, 0.2733, 0.5143, 0.9574, 0.7774, 0.6708, 0.9385, 0.8200, 0.8694]])\n",
      "metatensor([[0.4497, 0.4331, 0.3483, 0.9304, 0.7588, 0.5457, 0.9134, 0.6978, 0.7842]])\n",
      "metatensor([[0.5309, 0.5465, 0.4377, 0.8007, 0.6147, 0.4566, 0.8047, 0.5461, 0.4813]])\n",
      "metatensor([[0.5115, 0.5625, 0.4040, 0.7883, 0.6063, 0.4473, 0.7865, 0.5338, 0.4846]])\n",
      "metatensor([[0.5060, 0.6309, 0.2289, 0.8534, 0.6186, 0.3794, 0.8177, 0.5040, 0.5519]])\n",
      "metatensor([[0.4720, 0.5208, 0.4701, 0.7799, 0.6075, 0.5578, 0.7831, 0.5677, 0.5313]])\n",
      "metatensor([[0.5340, 0.7380, 0.1029, 0.9682, 0.7309, 0.3254, 0.9491, 0.5545, 0.6836]])\n",
      "metatensor([[0.5073, 0.6323, 0.2238, 0.8869, 0.6560, 0.4074, 0.8546, 0.5326, 0.6061]])\n",
      "metatensor([[0.4738, 0.5453, 0.4274, 0.7787, 0.6033, 0.5236, 0.7738, 0.5559, 0.5339]])\n",
      "metatensor([[0.5091, 0.6596, 0.1994, 0.8954, 0.6533, 0.3680, 0.8600, 0.5340, 0.6062]])\n",
      "metatensor([[0.4811, 0.5506, 0.3465, 0.8315, 0.6383, 0.4945, 0.8133, 0.5448, 0.5946]])\n",
      "metatensor([[0.4631, 0.5285, 0.4333, 0.7809, 0.6050, 0.5413, 0.7713, 0.5558, 0.5384]])\n",
      "metatensor([[0.4594, 0.4205, 0.5631, 0.8249, 0.6401, 0.6816, 0.8322, 0.6587, 0.5992]])\n",
      "metatensor([[0.4544, 0.4682, 0.3412, 0.9167, 0.7405, 0.5379, 0.8953, 0.6663, 0.7468]])\n",
      "metatensor([[0.4863, 0.5676, 0.3363, 0.8121, 0.6207, 0.4831, 0.7927, 0.5217, 0.5510]])\n",
      "metatensor([[0.4584, 0.5208, 0.4136, 0.8008, 0.6344, 0.5488, 0.7847, 0.5846, 0.6019]])\n",
      "metatensor([[0.4610, 0.5325, 0.4198, 0.7858, 0.6028, 0.5262, 0.7680, 0.5544, 0.5282]])\n",
      "metatensor([[0.4787, 0.5585, 0.3854, 0.7792, 0.5839, 0.4740, 0.7641, 0.5420, 0.5035]])\n",
      "metatensor([[0.4691, 0.5261, 0.4571, 0.7830, 0.6101, 0.5477, 0.7817, 0.5629, 0.5274]])\n",
      "metatensor([[0.5492, 0.5420, 0.4881, 0.8117, 0.6211, 0.4955, 0.8376, 0.5794, 0.4846]])\n",
      "metatensor([[0.4443, 0.4373, 0.3630, 0.9311, 0.7524, 0.5682, 0.9085, 0.6920, 0.7748]])\n",
      "metatensor([[0.4726, 0.4994, 0.3235, 0.9256, 0.7420, 0.5324, 0.9094, 0.6555, 0.7599]])\n",
      "metatensor([[0.4743, 0.5266, 0.4326, 0.7896, 0.6009, 0.5115, 0.7773, 0.5620, 0.5080]])\n",
      "metatensor([[0.4677, 0.4971, 0.5065, 0.7848, 0.6166, 0.6097, 0.7968, 0.5882, 0.5476]])\n",
      "metatensor([[0.4466, 0.4914, 0.4742, 0.7900, 0.6275, 0.6008, 0.7863, 0.5910, 0.5755]])\n",
      "metatensor([[0.5195, 0.6463, 0.1008, 0.9904, 0.8258, 0.4099, 0.9833, 0.6717, 0.8304]])\n",
      "metatensor([[0.4247, 0.4002, 0.5784, 0.8260, 0.6406, 0.7112, 0.8209, 0.6797, 0.6440]])\n",
      "metatensor([[0.4969, 0.5795, 0.3807, 0.7865, 0.5937, 0.4435, 0.7824, 0.5384, 0.4969]])\n",
      "metatensor([[0.4729, 0.5463, 0.4081, 0.7769, 0.5904, 0.4924, 0.7638, 0.5433, 0.5030]])\n",
      "metatensor([[0.4178, 0.2828, 0.2802, 0.9924, 0.8849, 0.6197, 0.9889, 0.8587, 0.9374]])\n",
      "metatensor([[0.4473, 0.4266, 0.5649, 0.8155, 0.6349, 0.6865, 0.8198, 0.6548, 0.5992]])\n",
      "metatensor([[0.4322, 0.4244, 0.5183, 0.8219, 0.6505, 0.6596, 0.8123, 0.6555, 0.6448]])\n",
      "metatensor([[0.4786, 0.4599, 0.5702, 0.7988, 0.6265, 0.6622, 0.8154, 0.6299, 0.5550]])\n",
      "metatensor([[0.4652, 0.4633, 0.2816, 0.9591, 0.7883, 0.5380, 0.9450, 0.7050, 0.8014]])\n",
      "metatensor([[0.4613, 0.5150, 0.4721, 0.7837, 0.6158, 0.5812, 0.7822, 0.5707, 0.5370]])\n",
      "metatensor([[0.4587, 0.4955, 0.3885, 0.8610, 0.6773, 0.5526, 0.8376, 0.6099, 0.6690]])\n",
      "metatensor([[0.3696, 0.2648, 0.7087, 0.8988, 0.6631, 0.7968, 0.8862, 0.8041, 0.7601]])\n",
      "metatensor([[0.4469, 0.3285, 0.1889, 0.9963, 0.9018, 0.5838, 0.9936, 0.8556, 0.9444]])\n",
      "metatensor([[0.4671, 0.5192, 0.4387, 0.7887, 0.5975, 0.5274, 0.7767, 0.5679, 0.5340]])\n",
      "metatensor([[0.3732, 0.2630, 0.7136, 0.9046, 0.6667, 0.8075, 0.8940, 0.8051, 0.7632]])\n",
      "metatensor([[0.4000, 0.3007, 0.4273, 0.9596, 0.7999, 0.6183, 0.9437, 0.8063, 0.8687]])\n",
      "metatensor([[0.4990, 0.5303, 0.4845, 0.7999, 0.6027, 0.5339, 0.8053, 0.5683, 0.4809]])\n",
      "metatensor([[0.4127, 0.3797, 0.5758, 0.8252, 0.6419, 0.6993, 0.8120, 0.7070, 0.6743]])\n",
      "metatensor([[0.4662, 0.5473, 0.3939, 0.7906, 0.6091, 0.5130, 0.7705, 0.5667, 0.5510]])\n",
      "metatensor([[0.5175, 0.5877, 0.3308, 0.8065, 0.6095, 0.4086, 0.7976, 0.5372, 0.4971]])\n",
      "metatensor([[0.5012, 0.5620, 0.4136, 0.7899, 0.5950, 0.4515, 0.7831, 0.5372, 0.4740]])\n",
      "metatensor([[0.4855, 0.5774, 0.3232, 0.8039, 0.5942, 0.4516, 0.7766, 0.5178, 0.5292]])\n",
      "metatensor([[0.4008, 0.2328, 0.2981, 0.9952, 0.9035, 0.6472, 0.9927, 0.8919, 0.9572]])\n",
      "metatensor([[0.4682, 0.5364, 0.4234, 0.7764, 0.5975, 0.5177, 0.7638, 0.5478, 0.5171]])\n",
      "metatensor([[0.4933, 0.5379, 0.4472, 0.7818, 0.5999, 0.4977, 0.7840, 0.5535, 0.4960]])\n",
      "metatensor([[0.4607, 0.4331, 0.2850, 0.9658, 0.8041, 0.5422, 0.9540, 0.7283, 0.8301]])\n",
      "metatensor([[0.5874, 0.5431, 0.5495, 0.8471, 0.6512, 0.4920, 0.8856, 0.6005, 0.4742]])\n",
      "metatensor([[0.4761, 0.5322, 0.4523, 0.7872, 0.5922, 0.5354, 0.7855, 0.5513, 0.5008]])\n",
      "metatensor([[0.5027, 0.6534, 0.2033, 0.8715, 0.6257, 0.3617, 0.8336, 0.4907, 0.5199]])\n",
      "metatensor([[0.3708, 0.2754, 0.5582, 0.9422, 0.7494, 0.6715, 0.9175, 0.8231, 0.8545]])\n",
      "metatensor([[0.4196, 0.2778, 0.2284, 0.9961, 0.9056, 0.6165, 0.9937, 0.8751, 0.9522]])\n",
      "metatensor([[0.4597, 0.4605, 0.3292, 0.9347, 0.7561, 0.5454, 0.9182, 0.6832, 0.7695]])\n",
      "metatensor([[0.4582, 0.5066, 0.4735, 0.7846, 0.6227, 0.6010, 0.7911, 0.5968, 0.5978]])\n",
      "metatensor([[0.4741, 0.5548, 0.3849, 0.7975, 0.5859, 0.4937, 0.7842, 0.5388, 0.5167]])\n",
      "metatensor([[0.4434, 0.4330, 0.3743, 0.9253, 0.7492, 0.5700, 0.9030, 0.6949, 0.7760]])\n",
      "metatensor([[0.4193, 0.4103, 0.5418, 0.8367, 0.6391, 0.6999, 0.8254, 0.6763, 0.6638]])\n",
      "metatensor([[0.4779, 0.5632, 0.3351, 0.8067, 0.6002, 0.4607, 0.7773, 0.5392, 0.5394]])\n",
      "metatensor([[0.4691, 0.5464, 0.4308, 0.7777, 0.6085, 0.5352, 0.7720, 0.5474, 0.5212]])\n",
      "metatensor([[0.4605, 0.5211, 0.4502, 0.7763, 0.6113, 0.5556, 0.7717, 0.5667, 0.5326]])\n",
      "metatensor([[0.4856, 0.5177, 0.3118, 0.9226, 0.7330, 0.5272, 0.9103, 0.6358, 0.7446]])\n",
      "metatensor([[0.4620, 0.5244, 0.4309, 0.7836, 0.6011, 0.5315, 0.7717, 0.5595, 0.5401]])\n",
      "metatensor([[0.4691, 0.5476, 0.4064, 0.7789, 0.5938, 0.5107, 0.7657, 0.5514, 0.5226]])\n",
      "metatensor([[0.4942, 0.5705, 0.3799, 0.7860, 0.5940, 0.4489, 0.7779, 0.5344, 0.4951]])\n",
      "metatensor([[0.4834, 0.5525, 0.3366, 0.8460, 0.6497, 0.5069, 0.8302, 0.5416, 0.6147]])\n",
      "metatensor([[0.4817, 0.5479, 0.4259, 0.7829, 0.5887, 0.4950, 0.7737, 0.5381, 0.4845]])\n",
      "metatensor([[0.4604, 0.5101, 0.4310, 0.8120, 0.6329, 0.5575, 0.7940, 0.5966, 0.6125]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (image1, image2, metadata, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(output)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(probs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\models.py:60\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, image1, image2, metadata)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image1, image2, metadata):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Pass both inputs through the shared model\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(image2)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Apply adaptive average pooling to both outputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\Warvito_MedicalNet-models_main\\medicalnet_models\\models\\resnet.py:54\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     52\u001b[0m     residual \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    719\u001b[0m     )\n\u001b[1;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\_tensor.py:1648\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1648\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (image1, image2, metadata, label) in enumerate(data_loader):\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the model\n",
    "        output = model(image1, image2, metadata)\n",
    "        probs = torch.sigmoid(output)\n",
    "    print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "# Create an iterator for the DataLoader\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "# Extract one batch\n",
    "batch = next(data_iter)\n",
    "\n",
    "# Unpack the batch (if applicable)\n",
    "img1, img2, metadata, labels = batch\n",
    "\n",
    "\n",
    "# Dummy image pair input\n",
    "image1_test = img1[0].to(\"cuda\")\n",
    "image2_test = img2[0].to(\"cuda\")\n",
    "metadata_test = metadata[0].to(\"cuda\")\n",
    "\n",
    "\n",
    "# Background for SHAP (used by DeepExplainer)\n",
    "image1_bg = img1[1:].to(\"cuda\")\n",
    "image2_bg = img2[1:].to(\"cuda\")\n",
    "metadata_bg = metadata[1:].to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'monai.data.meta_tensor.MetaTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(image2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrapped_model = SiameseWrapper(model).to(\"cuda\")\n",
    "\n",
    "# Use DeepExplainer for PyTorch models\n",
    "explainer = shap.GradientExplainer(\n",
    "    wrapped_model,\n",
    "    data=(image1_bg, image2_bg, metadata_bg)\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values((image1_test, image2_test, metadata_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\P095550/.cache\\torch\\hub\\Warvito_MedicalNet-models_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SiameseWrapper.forward() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Explain the image input (we need to make sure that the image tensor requires gradients)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m image_input\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m image_attr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Now explain the clinical input (again, ensure the tensor requires gradients)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m clinical_input\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\captum\\log\\dummy_log.py:39\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# pyre-fixme[53]: Captured variable `func` is not annotated.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# pyre-fixme[3]: Return type must be annotated.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:289\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[0;32m    277\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m         num_examples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_baselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[0;32m    299\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:368\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[0;32m    365\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[0;32m    377\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    378\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[0;32m    381\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\captum\\_utils\\gradient.py:128\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# _run_forward may return future of Tensor,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# but we don't support it here now\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# And it will fail before here.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m cast(Tensor, outputs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\captum\\_utils\\common.py:588\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    585\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    586\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 588\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# pyre-fixme[60]: Concatenation not yet support for multiple variadic\u001b[39;49;00m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#  tuples: `*inputs, *additional_forward_args`.\u001b[39;49;00m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, torch\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mthen(\u001b[38;5;28;01mlambda\u001b[39;00m x: _select_targets(x\u001b[38;5;241m.\u001b[39mvalue(), target))\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\P095550\\OneDrive - Amsterdam UMC\\Documenten\\GitHub\\CRLM-morph-features\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mTypeError\u001b[0m: SiameseWrapper.forward() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from captum.attr import IntegratedGradients\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "# Instantiate the base model (e.g., ResNet or other feature extractor)\n",
    "\n",
    "resnet_model = torch.hub.load('Warvito/MedicalNet-models', 'medicalnet_resnet10')\n",
    "\n",
    "# Remove the final classification layer (fc) to keep only the encoder part\n",
    "encoder = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "\n",
    "model = SiameseNetwork(encoder)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location='cpu'))\n",
    "\n",
    "wrapped_model = SiameseWrapper(model)\n",
    "\n",
    "wrapped_model.eval()\n",
    "\n",
    "\n",
    "# Sample input\n",
    "image_input = img1[0]\n",
    "clinical_input = metadata[0]\n",
    "\n",
    "# Use Integrated Gradients to explain the image input\n",
    "ig = IntegratedGradients(wrapped_model)\n",
    "\n",
    "# Explain the image input (we need to make sure that the image tensor requires gradients)\n",
    "image_input.requires_grad = True\n",
    "image_attr, _ = ig.attribute((img1[0], img2[0], metadata[0]), target=0, return_convergence_delta=True)\n",
    "\n",
    "# Now explain the clinical input (again, ensure the tensor requires gradients)\n",
    "clinical_input.requires_grad = True\n",
    "clinical_attr, _ = ig.attribute(clinical_input, target=0, return_convergence_delta=True)\n",
    "\n",
    "# Output the explanations\n",
    "print(\"Image Attribution:\", image_attr)\n",
    "print(\"Clinical Data Attribution:\", clinical_attr)\n",
    "\n",
    "# You can visualize or process the attributions further\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
